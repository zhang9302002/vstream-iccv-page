<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Flash-VStream: Efficient Real-Time Understanding for Long Video Streams">
  <meta name="keywords" content="Flash-VStream">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Flash-VStream: Efficient Real-Time Understanding for Long Video Streams</title>
  <link rel="icon" href="./static/images/logo_small.jpeg" type="image/jpeg">


  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.ico"> -->
  <!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h3 class="title is-3 publication-title" style="color: #b24a8a;"><b>[ICCV 2025]</b></h3>
            <div style="position: relative; width: 100%; display: flex; align-items: center; min-height: 80px;">
              <img src="static/images/logo.jpg" alt="Flash-VStream Logo"
                  style="height: 80px; position: absolute; left: -10%; top: 50%; transform: translateY(-50%);">
              <h1 class="title is-1 publication-title" style="margin: 0 auto; text-align: center;">
                <span style="color: #177cb0;">Flash-VStream</span>: Efficient Real-Time Understanding for Long Video Streams
              </h1>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://zhang9302002.github.io/">Haoji Zhang </a><sup>1*</sup>,</span>
              <span class="author-block">
                <a href="https://github.com/InvincibleWyq/">Yiqin Wang</a><sup>1*</sup>,</span>
              <span class="author-block">
                <a href="https://andytang15.github.io/">Yansong Tang </a><sup>1&#9993;</sup>,</span>
              <span class="author-block">
                <a href="https://yongliu20.github.io/">Yong Liu</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://sites.google.com/site/jshfeng/home">Jiashi Feng</a><sup>3</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com.sg/citations?user=OEZ816YAAAAJ&hl=en">Xiaojie Jin</a><sup>2,3&#9993;&dagger;</sup></span>
            </div>

            <div class="is-size-6 publication-authors">
              <span class="author-block"><sup>1</sup>Tsinghua University,</span>
              <span class="author-block"><sup>2</sup>Beijing Jiaotong University,</span>
              <span class="author-block"><sup>3</sup>ByteDance Seed</span>
            </div>

            <div class="is-size-6 publication-authors">
              <span class="author-block"><sup>*</sup>Equal contribution,</span>
              <span class="author-block"><sup>&#9993;</sup>Corresponding authors,</span>
              <span class="author-block"><sup>&dagger;</sup>Project leader.</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="http://arxiv.org/abs/2506.23825"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>ArXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/IVGSZ/Flash-VStream"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </div>

            </div>

            <div class="columns is-centered has-text-centered">
              <div class="column is-four-fifths">
                <div class="content has-text-justified">
                  Our previous work includes:
                  <ul>
                    <li>
                      <b>2024.06 Flash-VStream-LLaVA</b>
                      <a href="https://arxiv.org/abs/2406.08085v2">[ArXiv]</a>
                      <a href="https://github.com/IVGSZ/Flash-VStream">[Code]</a>
                      <a href="https://invinciblewyq.github.io/vstream-page/">[Project Page]</a>
                    </li>
                    <li>
                      <b>2024.06 1st Place of CVPR24 workshop</b>
                      <a href="https://arxiv.org/abs/2407.00603">[ArXiv]</a>
                      <a href="https://sites.google.com/view/loveucvpr24/track1">
                        [CVPR24 LOVEU Challenge Track 1]
                      </a>
                      <a href="https://github.com/user-attachments/assets/510f7ed9-72ad-434a-a289-6aa41b45c1e7">
                        [Certification]
                      </a>
                    </li>
                  </ul>
                </div>
              </div>
            </div>


          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="container is-max-desktop content has-text-centered">
    <!-- TL;DR. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">TL; DR</h2>
        <div class="content has-text-justified">
          <p>
            <strong>
              We proposed <span style="color: #177cb0;">Flash-VStream</span>, an efficient VLM with a novel Flash Memory mechanism that enables <span style="color: #ca6924;">real-time</span> understanding and Q&A of extremely long video streams.
              Our model achieves outstanding efficiency on EgoSchema, MLVU, LVBench, MVBench and Video-MME Benchmarks.
            </strong>
          </p>
        </div>
      </div>
    </div>

    <div class="double-blocks">
      <div class="content has-text-centered">
        <img src="./static/images/teaser.png" alt="Flash-VStream Teaser" width="40%">
        <figcaption>
          <b>Comparison with previous methods.</b> <span style="color: #177cb0;">Flash-VStream</span> can understand long videos accurately in an online manner. Here ‚ÄúC‚Äù denotes critical clues for questions.
        </figcaption>
      </div>

      <div class="content has-text-centered">
        <img src="./static/images/effi.png" alt="Flash-VStream Efficiency Exp" width="40%">
        <figcaption>
          <b>Response latency / Accuracy on EgoSchema v.s. Inference cost.</b> <span style="color: #177cb0;">Flash-VStream</span> can respond to user queries in real time while maintaining outstanding performance.
        </figcaption>
      </div>
    </div>
  </section>

  <section class="">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Benefiting from the advances in large language models and cross-modal alignment, existing multimodal large language models have achieved prominent performance in image and short video understanding. However, the understanding of long videos is still challenging, as their long-context nature results in significant computational and memory overhead. Most existing work treats long videos in the same way as short videos, which is inefficient for real-world applications and hard to generalize to even longer videos. To address these issues, we propose <span style="color: #177cb0;">Flash-VStream</span>, an efficient video language model capable of processing extremely long videos and responding to user queries in real time. Particularly, we design a Flash Memory module, containing a low-capacity context memory to aggregate long-context temporal information and model the distribution of information density, and a high-capacity augmentation memory to retrieve detailed spatial information based on this distribution. Compared to existing models, <span style="color: #177cb0;">Flash-VStream</span> achieves significant reductions in inference latency. Extensive experiments on long video benchmarks and comprehensive video benchmarks, i.e., EgoSchema, MLVU, LVBench, MVBench and Video-MME, demonstrate the state-of-the-art performance and outstanding efficiency of our method.
              Code is available <a href="https://github.com/IVGSZ/Flash-VStream">here</a>.
            </p>
          </div>
        </div>
      </div>

    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">

      <!-- Main text. -->
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3 has-text-centered">Architecture</h2>
          <div class="content has-text-justified">
            <img src="./static/images/framework.png" alt="Pipeline" width="100%">
            <figcaption>
              <strong>Overview of <span style="color: #177cb0;">Flash-VStream</span> two-process framework.</strong>
              The frame handler process continuously encodes new frames.
              The question handler process asynchronously responds to human inquiries in real-time. 
              Flash Memory is composed of interleaved Context Synopsis Memory and Detail Augmentation Memory, organized in chronological order. CSM is updated by clustering low resolution feature maps on an inter-frame level. DAM is updated by retrieving high resolution feature maps of the most informative frames from a feature bank.
            </figcaption>
          </div>

          <h2 class="title is-3 has-text-centered">Efficient Long Video VQA</h2>

            <div class="content has-text-centered">
              <img src="./static/images/performance1.png" alt="Results" width="80%">
            </div>

            <div class="content has-text-centered">
              <img src="./static/images/performance2.png" alt="Results" width="80%">
            </div>

            <div class="content has-text-centered">
              <img src="./static/images/performance3.png" alt="Results" width="80%">
            </div>

          <h2 class="title is-3 has-text-centered">Ablation Studies</h2>

            <div class="content has-text-centered">
              <img src="./static/images/ablation1.png" alt="Results" width="80%">
            </div>
            <div class="content has-text-centered">
              <img src="./static/images/ablation2.png" alt="Results" width="80%">
            </div>

          <h2 class="title is-3 has-text-centered">Case Study</h2>

            <div class="content has-text-centered">
              <img src="./static/images/case.png" alt="Results" width="80%">
              <figcaption class="content has-text-justified">
              </br>
                <strong> Left: PCA visualization of the Flash Memory distribution. </strong>
                Each point in it stands for a feature map of a single frame or a slice of memory. The CSM and DAM appropriately represent the distributional characteristics of the feature clusters. 
                <strong> Right: Case study of Q&A. </strong>
                Different types of question answering cases show exceptional proficiency of the <span style="color: #177cb0;">Flash-VStream</span> model.
              </figcaption>
            </div>


        </div>
      </div>
    </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <p>If you find these projects useful in your research, please consider citing:</p>
      <pre>
<code>@article{zhang2025flashvstream,
    title={Flash-VStream: Efficient Real-Time Understanding for Long Video Streams}, 
    author={Haoji Zhang and Yiqin Wang and Yansong Tang and Yong Liu and Jiashi Feng and Xiaojie Jin},
    journal={arXiv preprint arXiv:2506.23825},
    year={2025},
}
@article{zhang2024flashvstream,
    title={Flash-VStream: Memory-Based Real-Time Understanding for Long Video Streams},
    author={Zhang, Haoji and Wang, Yiqin and Tang, Yansong and Liu, Yong and Feng, Jiashi and Dai, Jifeng and Jin, Xiaojie},
    journal={arXiv preprint arXiv:2406.08085},
    year={2024}
}</code>
</pre>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content has-text-centered">
            <p>
              &copy; Haoji Zhang, Yiqin Wang 2025. Adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>